{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Nitin/Desktop/Desktop FOlder/Study Material/Semester 2/BIA 660/Project work/515k-hotel-reviews-data-in-europe/df_Hotel_Reviews_undersample_notags.csv\")#, sep=',',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145406 entries, 0 to 145405\n",
      "Data columns (total 4 columns):\n",
      "Unnamed: 0         145406 non-null int64\n",
      "Negative_Review    145406 non-null object\n",
      "Positive_Review    145406 non-null object\n",
      "Reviewer_Score     145406 non-null float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "from nltk.corpus import stopwords\n",
    "import nltk, re, string\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stop = set(STOP_WORDS)\n",
    "\n",
    "\n",
    "\n",
    "docs=data['Positive_Review']\n",
    "#docs=data['Negative_Review']\n",
    "#target=data[3]\n",
    "\n",
    "def get_doc_tokens(doc,lem):\n",
    "        #stop_words = stop\n",
    "        tokens=[token.strip()\n",
    "                for token in nltk.word_tokenize(doc.lower())\n",
    "                if token.strip() not in stop and\n",
    "                token.strip() not in string.punctuation]\n",
    "        \n",
    "        tagged_tokens= nltk.pos_tag(tokens)\n",
    "        \n",
    "        def get_wordnet_pos(pos_tag):\n",
    "    \n",
    "            if pos_tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "\n",
    "            elif pos_tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "\n",
    "            elif pos_tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "\n",
    "            elif pos_tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:\n",
    "                return wordnet.NOUN\n",
    "        \n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        if lem == True:\n",
    "            negative_lemma=[wordnet_lemmatizer.lemmatize(word, get_wordnet_pos(tag))      \n",
    "            for (word, tag) in tagged_tokens \\\n",
    "            if word not in stop and \\\n",
    "            word not in string.punctuation]\n",
    "        else:\n",
    "            negative_lemma = tokens\n",
    "\n",
    "        return negative_lemma\n",
    "\n",
    "\n",
    "docs_tokens=[get_doc_tokens(doc,True) for doc in docs] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#docs_tokens.to_csv(\"C:/Users/Nitin/Desktop/Desktop FOlder/Study Material/Semester 2/BIA 660/Project work/515k-hotel-reviews-data-in-europe/positive_lemma.csv\")\n",
    "\n",
    "import csv\n",
    "#with open('C:/Users/Nitin/Desktop/Desktop FOlder/Study Material/Semester 2/BIA 660/Project work/515k-hotel-reviews-data-in-europe/positive_lemma.csv', 'wb') as output:\n",
    "with open(\"C:/Users/Nitin/Desktop/Desktop FOlder/Study Material/Semester 2/BIA 660/Project work/515k-hotel-reviews-data-in-europe/positive_lemma1.csv\", \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in docs_tokens:\n",
    "        writer.writerow([val])   \n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"C:/Users/Nitin/Desktop/Desktop FOlder/Study Material/Semester 2/BIA 660/Project work/515k-hotel-reviews-data-in-europe/positive_lemma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = pd.read_csv(\"C:/Users/Nitin/Desktop/Desktop FOlder/Study Material/Semester 2/BIA 660/Project work/515k-hotel-reviews-data-in-europe/positive_lemma1.csv\")#, sep=',',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['park', 'outside', 'hotel', 'beautiful']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['great', 'location', 'nice', 'surroundings', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['room', 'spacious', 'bright', 'hotel', 'locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['style', 'location', 'room']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['comfy', 'bed', 'good', 'location']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     positive_review\n",
       "0          ['park', 'outside', 'hotel', 'beautiful']\n",
       "1  ['great', 'location', 'nice', 'surroundings', ...\n",
       "2  ['room', 'spacious', 'bright', 'hotel', 'locat...\n",
       "3                      ['style', 'location', 'room']\n",
       "4               ['comfy', 'bed', 'good', 'location']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = pd.read_csv(\"C:/Users/Nitin/Desktop/Desktop FOlder/Study Material/Semester 2/BIA 660/Project work/515k-hotel-reviews-data-in-europe/negative_lemma.csv\")#, sep=',',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['angry', 'post', 'available', 'possible', 'si...\n",
       "1    ['room', 'dirty', 'afraid', 'walk', 'barefoot'...\n",
       "2    ['clean', 'change', 'sheet', 'duvet', 'everyda...\n",
       "3    ['6', '30', 'start', 'big', 'noise', 'worker',...\n",
       "4    ['floor', 'room', 'filfy', 'dirty', 'basic', '...\n",
       "Name: negative_review, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = positive['positive_review']\n",
    "negative = negative['negative_review']\n",
    "negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['angry', 'post', 'available', 'possible', 'si...\n",
       "1    ['room', 'dirty', 'afraid', 'walk', 'barefoot'...\n",
       "2    ['clean', 'change', 'sheet', 'duvet', 'everyda...\n",
       "3    ['6', '30', 'start', 'big', 'noise', 'worker',...\n",
       "4    ['floor', 'room', 'filfy', 'dirty', 'basic', '...\n",
       "Name: negative_review, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sentiment = pd.read_csv(\"C:/Users/Nitin/Desktop/Desktop FOlder/Study Material/Semester 2/BIA 660/Project work/515k-hotel-reviews-data-in-europe/positive_sentiment.csv\")#, sep=',',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sentiment = pd.read_csv(\"C:/Users/Nitin/Desktop/Desktop FOlder/Study Material/Semester 2/BIA 660/Project work/515k-hotel-reviews-data-in-europe/df_Hotel_Reviews_undersample_notags.csv\")#, sep=',',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_review = p_sentiment['Positive_Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_review = n_sentiment['Negative_Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         park outside hotel beautiful\n",
       "1    great location nice surroundings bar restauran...\n",
       "2    room spacious bright hotel located quiet beaut...\n",
       "3                                 style location rooms\n",
       "4                              comfy bed good location\n",
       "Name: Positive_Review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=True, norm=None, use_idf=True)\n",
    "TI_P = tfidf.fit_transform(positive)\n",
    "\n",
    "#v = TfidfVectorizer()\n",
    "#x = v.fit_transform(df['sent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12097)\t2.04286011413\n",
      "  (0, 17232)\t2.40284658749\n",
      "  (0, 4882)\t3.41205210445\n",
      "  (0, 18930)\t2.21982607212\n",
      "  (0, 19060)\t3.87980246205\n",
      "  (0, 3485)\t5.8520233867\n",
      "  (0, 6087)\t5.29190470712\n",
      "  (0, 15791)\t5.74683894288\n"
     ]
    }
   ],
   "source": [
    "print(TI_P[100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_topics = 100\n",
    "lda_pipe = Pipeline([('tfidf', TfidfVectorizer(min_df=0.001)),\n",
    "                     ('lda', LatentDirichletAllocation(n_components=num_of_topics)),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitin\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "XP = lda_pipe.fit_transform(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfp = lda_pipe.named_steps['tfidf']\n",
    "ldap = lda_pipe.named_steps['lda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def print_topic_words(components, vocab, num_topics=10, num_of_word_per_topic=10):\n",
    "    topic_words = []\n",
    "    vocab_array = np.array(vocab)\n",
    "\n",
    "    for topic in components:\n",
    "        word_idx = np.argsort(topic)[::-1][:num_of_word_per_topic]\n",
    "        topic_words.append((vocab_array[word_idx]).tolist())\n",
    "        \n",
    "    for topic, words in list(zip(['Topic_{}'.format(i+1) for i in range(num_topics)], topic_words))[:10]:\n",
    "        print(topic, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic_1 ['especially', 'extra', 'absolutely', 'complimentary', 'pay', 'hall', 'wine', 'chocolate', 'receive', 'room']\n",
      "Topic_2 ['amenity', 'exactly', 'young', 'exceptional', 'express', 'explore', 'experience', 'expensive', 'expectation', 'expect']\n",
      "Topic_3 ['little', 'outside', 'bit', 'luxurious', 'internet', 'ready', 'different', 'inside', 'middle', 'environment']\n",
      "Topic_4 ['felt', 'upgraded', 'home', 'double', 'tasty', 'single', 'market', 'daughter', 'evening', 'actually']\n",
      "Topic_5 ['young', 'excellent', 'express', 'explore', 'experience', 'expensive', 'expectation', 'expect', 'executive', 'exceptionally']\n",
      "Topic_6 ['comfort', 'efficient', 'help', 'warm', 'staff', 'friendly', 'receptionist', 'fast', 'liked', 'general']\n",
      "Topic_7 ['walk', 'distance', 'short', 'decent', 'tv', 'pretty', 'noise', 'restaurant', 'good', 'excellent']\n",
      "Topic_8 ['light', 'refurbish', 'newly', 'young', 'explore', 'experience', 'expensive', 'expectation', 'expect', 'executive']\n",
      "Topic_9 ['control', 'temperature', 'young', 'excellent', 'explore', 'experience', 'expensive', 'expectation', 'expect', 'executive']\n",
      "Topic_10 ['young', 'excellent', 'express', 'explore', 'experience', 'expensive', 'expectation', 'expect', 'executive', 'exceptionally']\n"
     ]
    }
   ],
   "source": [
    "print_topic_words(ldap.components_, tfidfp.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitin\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "XN = lda_pipe.fit_transform(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_n = lda_pipe.named_steps['tfidf']\n",
    "lda_n = lda_pipe.named_steps['lda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic_1 ['wifi', 'price', 'free', 'option', 'fine', 'excellent', 'breakfast', 'compare', 'child', 'crowd']\n",
      "Topic_2 ['bad', 'uncomfortable', 'ok', 'experience', 'bed', 'worn', 'promise', 'unprofessional', 'room', 'small']\n",
      "Topic_3 ['park', 'think', 'car', 'tired', 'hotel', 'rate', 'consider', 'weather', 'room', 'line']\n",
      "Topic_4 ['breakfast', 'include', 'soft', 'euro', 'eat', 'able', 'step', 'closet', 'fully', 'queen']\n",
      "Topic_5 ['zero', 'exit', 'everyday', 'exactly', 'example', 'excellent', 'excuse', 'executive', 'existent', 'expect']\n",
      "Topic_6 ['have', 'table', 'machine', 'standard', 'improve', 'breakfast', 'narrow', 'website', 'general', 'room']\n",
      "Topic_7 ['zero', 'exit', 'everyday', 'exactly', 'example', 'excellent', 'excuse', 'executive', 'existent', 'expect']\n",
      "Topic_8 ['shower', 'water', 'hot', 'difficult', 'access', 'desk', 'stair', 'room', 'key', 'distance']\n",
      "Topic_9 ['room', 'bag', 'hotel', 'lady', 'dust', 'finish', 'party', 'till', 'ask', 'appreciate']\n",
      "Topic_10 ['zero', 'exit', 'everyday', 'exactly', 'example', 'excellent', 'excuse', 'executive', 'existent', 'expect']\n"
     ]
    }
   ],
   "source": [
    "print_topic_words(lda_n.components_, tfidf_n.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.03356689,  0.00127422,  0.00127422,  0.37459594,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.03788573,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.01576528,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.01807539,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.01763457,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.01796358,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.03032881,\n",
       "        0.00127422,  0.00127422,  0.00127422,  0.00127422,  0.01615196,\n",
       "        0.00127422,  0.00127422,  0.02721447,  0.00127422,  0.00127422,\n",
       "        0.28314058,  0.00127422,  0.00127422,  0.00127422,  0.00127422,\n",
       "        0.00127422,  0.00127422,  0.01554527,  0.00127422,  0.00127422])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XN[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'LatentDirichletAllocation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-6a58be87b4ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mXP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLatentDirichletAllocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'LatentDirichletAllocation'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
