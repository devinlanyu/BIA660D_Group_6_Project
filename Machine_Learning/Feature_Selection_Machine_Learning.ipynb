{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/richard/Desktop/Final_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=df['Score']\n",
    "DF1=df.drop(['Name','Nationality','Score','friends','solo', 'Date_new'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[DF1['Topic'].notnull()]\n",
    "df_new.to_csv('/Users/richard/Desktop/Final_Data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    '''a function for removing punctuation'''\n",
    "    import string\n",
    "    # replacing the punctuations with no space, \n",
    "    # which in effect deletes the punctuation marks \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    # return the text stripped of punctuation marks\n",
    "    return text.translate(translator)\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "def stopwords(text):\n",
    "    '''a function for removing the stopword'''\n",
    "    # removing the stop words and lowercasing the selected words\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    # joining the list of words with space separator\n",
    "    return \" \".join(text)\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(text):    \n",
    "    '''a function which stems each word in the given text'''\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_new['Topic']=df_new['Topic'].apply(remove_punctuation)\n",
    "df_new['Topic']=df_new['Topic'].apply(stopwords)\n",
    "df_new['Topic']=df_new['Topic'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "data = cv.fit_transform(df_new.Topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF2=pd.concat([pd.DataFrame(data.toarray()), df_new], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2.drop(['Name','Nationality','Score','friends','solo', 'Date_new','Topic'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new=[]\n",
    "for i in y:\n",
    "    if i>=8:\n",
    "        a=2\n",
    "    elif 6<i<8:\n",
    "        a=1\n",
    "    else:\n",
    "        a=0\n",
    "    y_new.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2=DF2.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(DF2,y_new,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr = LogisticRegression()\n",
    "param_grid = {'C': np.linspace(1, 100, 1), 'penalty': ['l1', 'l2']}\n",
    "grid_lr = GridSearchCV(lr, param_grid=param_grid, cv=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([ 1.]), 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=grid_lr.best_estimator_\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15   1  26]\n",
      " [ 10   6  91]\n",
      " [  5   6 401]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr=lr.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LRcm=confusion_matrix(y_test,y_pred_lr)\n",
    "print(LRcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752228163993\n"
     ]
    }
   ],
   "source": [
    "precision=LRcm.trace()/LRcm.sum()\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#sample_leaf_options = [1,5,10,50,100,200,500]\n",
    "#for leaf_size in sample_leaf_options:\n",
    "    #model = RandomForestClassifier(n_estimators = 200, oob_score = True, n_jobs = -1,random_state =50,max_features = \"auto\", min_samples_leaf = leaf_size)\n",
    "    #model.fit(DF2,y_new)\n",
    "    #print(cross_val_score(model, X=DF2, y=y_new, cv=10, scoring='accuracy').mean())\n",
    "classifier=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.748811 using {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "#tuning parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "n_estimators_range=[10,100,500,1000]\n",
    "max_depth_range=[None,5,8,15,30]\n",
    "min_samples_split_range=[2,5,10,50,100]\n",
    "min_samples_leaf_range=[1,2,5,10]\n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth=max_depth_range, min_samples_leaf=min_samples_leaf_range, min_samples_split=min_samples_split_range)\n",
    "grid = GridSearchCV(estimator=classifier, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(x_train,y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "    #print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "#(Result is too long on github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model=grid.best_estimator_\n",
    "rfc_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12   2  28]\n",
      " [  6  11  90]\n",
      " [  4   8 400]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_rfc=rfc_model.predict(x_test)\n",
    "cm_rfc=confusion_matrix(y_test,y_pred_rfc)\n",
    "print(cm_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754010695187\n"
     ]
    }
   ],
   "source": [
    "precision_rfc=cm_rfc.trace()/cm_rfc.sum()\n",
    "print(precision_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# SETTINGS - CHANGE THESE TO GET SOMETHING MEANINGFUL\n",
    "ITERATIONS = 10 # 1000\n",
    "TRAINING_SIZE = 100000 # 20000000\n",
    "TEST_SIZE = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x_train['Review_times']=pd.to_numeric(x_train['Review_times'])\n",
    "x_test['Review_times']=pd.to_numeric(x_test['Review_times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator = xgb.XGBClassifier(\n",
    "        n_jobs = 1,\n",
    "        objective = 'multi:softmax',\n",
    "        silent=1,\n",
    "        tree_method='approx'\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': (0, 10),\n",
    "        'max_depth': (0, 50),\n",
    "        'max_delta_step': (0, 20),\n",
    "        'subsample': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': (0, 5),\n",
    "        'n_estimators': (50, 100),\n",
    "        'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "    },    \n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs = 3,\n",
    "    n_iter = ITERATIONS,   \n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner.best_score_, 4),\n",
    "        bayes_cv_tuner.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ROC-AUC: 0.7429\n",
      "Best params: {'colsample_bylevel': 0.41600291926478072, 'colsample_bytree': 0.73044848574555188, 'gamma': 0.13031389926541354, 'learning_rate': 0.042815319280763466, 'max_delta_step': 13, 'max_depth': 21, 'min_child_weight': 2, 'n_estimators': 87, 'reg_alpha': 5.4975577392897861e-07, 'reg_lambda': 0.059360706359120489, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216}\n",
      "\n",
      "Model #2\n",
      "Best ROC-AUC: 0.746\n",
      "Best params: {'colsample_bylevel': 0.83901447199775159, 'colsample_bytree': 0.88448212460705367, 'gamma': 4.3586846084807948e-07, 'learning_rate': 0.79881794627812419, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.00052669830037015467, 'reg_lambda': 276.54244755742252, 'scale_pos_weight': 0.30164107718431421, 'subsample': 0.99237105986371343}\n",
      "\n",
      "Model #3\n",
      "Best ROC-AUC: 0.746\n",
      "Best params: {'colsample_bylevel': 0.83901447199775159, 'colsample_bytree': 0.88448212460705367, 'gamma': 4.3586846084807948e-07, 'learning_rate': 0.79881794627812419, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.00052669830037015467, 'reg_lambda': 276.54244755742252, 'scale_pos_weight': 0.30164107718431421, 'subsample': 0.99237105986371343}\n",
      "\n",
      "Model #4\n",
      "Best ROC-AUC: 0.746\n",
      "Best params: {'colsample_bylevel': 0.83901447199775159, 'colsample_bytree': 0.88448212460705367, 'gamma': 4.3586846084807948e-07, 'learning_rate': 0.79881794627812419, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.00052669830037015467, 'reg_lambda': 276.54244755742252, 'scale_pos_weight': 0.30164107718431421, 'subsample': 0.99237105986371343}\n",
      "\n",
      "Model #5\n",
      "Best ROC-AUC: 0.746\n",
      "Best params: {'colsample_bylevel': 0.83901447199775159, 'colsample_bytree': 0.88448212460705367, 'gamma': 4.3586846084807948e-07, 'learning_rate': 0.79881794627812419, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.00052669830037015467, 'reg_lambda': 276.54244755742252, 'scale_pos_weight': 0.30164107718431421, 'subsample': 0.99237105986371343}\n",
      "\n",
      "Model #6\n",
      "Best ROC-AUC: 0.746\n",
      "Best params: {'colsample_bylevel': 0.83901447199775159, 'colsample_bytree': 0.88448212460705367, 'gamma': 4.3586846084807948e-07, 'learning_rate': 0.79881794627812419, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.00052669830037015467, 'reg_lambda': 276.54244755742252, 'scale_pos_weight': 0.30164107718431421, 'subsample': 0.99237105986371343}\n",
      "\n",
      "Model #7\n",
      "Best ROC-AUC: 0.746\n",
      "Best params: {'colsample_bylevel': 0.83901447199775159, 'colsample_bytree': 0.88448212460705367, 'gamma': 4.3586846084807948e-07, 'learning_rate': 0.79881794627812419, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.00052669830037015467, 'reg_lambda': 276.54244755742252, 'scale_pos_weight': 0.30164107718431421, 'subsample': 0.99237105986371343}\n",
      "\n",
      "Model #8\n",
      "Best ROC-AUC: 0.746\n",
      "Best params: {'colsample_bylevel': 0.83901447199775159, 'colsample_bytree': 0.88448212460705367, 'gamma': 4.3586846084807948e-07, 'learning_rate': 0.79881794627812419, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.00052669830037015467, 'reg_lambda': 276.54244755742252, 'scale_pos_weight': 0.30164107718431421, 'subsample': 0.99237105986371343}\n",
      "\n",
      "Model #9\n",
      "Best ROC-AUC: 0.746\n",
      "Best params: {'colsample_bylevel': 0.83901447199775159, 'colsample_bytree': 0.88448212460705367, 'gamma': 4.3586846084807948e-07, 'learning_rate': 0.79881794627812419, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.00052669830037015467, 'reg_lambda': 276.54244755742252, 'scale_pos_weight': 0.30164107718431421, 'subsample': 0.99237105986371343}\n",
      "\n",
      "Model #10\n",
      "Best ROC-AUC: 0.746\n",
      "Best params: {'colsample_bylevel': 0.83901447199775159, 'colsample_bytree': 0.88448212460705367, 'gamma': 4.3586846084807948e-07, 'learning_rate': 0.79881794627812419, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.00052669830037015467, 'reg_lambda': 276.54244755742252, 'scale_pos_weight': 0.30164107718431421, 'subsample': 0.99237105986371343}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = bayes_cv_tuner.fit(x_train.values, y_train, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model=XGBClassifier(colsample_bylevel=0.83901447199775159, colsample_bytree=0.88448212460705367, \n",
    "                        gamma= 4.3586846084807948e-07, learning_rate= 0.79881794627812419, \n",
    "                        max_delta_step=17, max_depth= 3, min_child_weight=1, \n",
    "                        n_estimators= 68, reg_alpha= 0.00052669830037015467, reg_lambda= 276.54244755742252, \n",
    "                        scale_pos_weight=0.30164107718431421, subsample=0.99237105986371343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "       colsample_bylevel=0.8390144719977516,\n",
       "       colsample_bytree=0.8844821246070537, gamma=4.358684608480795e-07,\n",
       "       learning_rate=0.7988179462781242, max_delta_step=17, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=68, n_jobs=1,\n",
       "       nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0.0005266983003701547, reg_lambda=276.5424475574225,\n",
       "       scale_pos_weight=0.3016410771843142, seed=None, silent=True,\n",
       "       subsample=0.9923710598637134)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(x_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11   6  25]\n",
      " [  8  17  82]\n",
      " [  5  21 386]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgboost=xgb_model.predict(x_test.values)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "XGboost_cm=confusion_matrix(y_test,y_pred_xgboost)\n",
    "print(XGboost_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737967914439\n"
     ]
    }
   ],
   "source": [
    "precision_xgboost=XGboost_cm.trace()/XGboost_cm.sum()\n",
    "print(precision_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
